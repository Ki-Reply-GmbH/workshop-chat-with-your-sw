{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "import ast\n",
    "from pathlib import Path\n",
    "from typing import Iterator, Any, Optional, List, NotRequired, Union\n",
    "import re\n",
    "\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def list_files(directory):\n",
    "    # Expand user home directory symbol '~' if present\n",
    "    directory = os.path.expanduser(directory)\n",
    "    \n",
    "    # Get the absolute path of the directory\n",
    "    abs_directory = os.path.abspath(directory)\n",
    "    \n",
    "    # Check if the provided path is a directory\n",
    "    if not os.path.isdir(abs_directory):\n",
    "        return f\"The path {abs_directory} is not a valid directory.\"\n",
    "\n",
    "    # Define the file extensions to track\n",
    "    file_extensions = ['.py', '.md', 'rst']\n",
    "    \n",
    "    # Use glob to list all files in the directory and subdirectories\n",
    "    files = [file for file in glob.glob(os.path.join(abs_directory, '**', '*'), recursive=True) if os.path.isfile(file) and os.path.splitext(file)[1] in file_extensions]\n",
    "    \n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def chunk_text(text, max_length=1000):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=max_length, chunk_overlap=200)\n",
    "    return splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = list_files(\"./resources\")\n",
    "\n",
    "list_chunk = []\n",
    "for file in file_list:\n",
    "    content = read_file(file)\n",
    "    chunks = chunk_text(content, max_length=1000)\n",
    "    list_chunk.extend(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=\"\",\n",
    "    openai_organization=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_texts(\n",
    "    texts=list_chunk,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "    You're a helpful assistant that informs the user about the code base.\n",
    "\n",
    "    Only use the context and if the context is not sufficient, please respond with:\n",
    "    'Sorry I can't answer your question'.\n",
    "    Use the following context:\n",
    "    ```\n",
    "    {context}\n",
    "    ```\n",
    "\n",
    "    The question from the user:\n",
    "    ```\n",
    "    {question}\n",
    "    ```\n",
    "\n",
    "    Your answer:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o\",\n",
    "    openai_api_key=\"\",\n",
    "    openai_organization=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs): \n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\" : retriever | format_docs, \"question\" : RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser () \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The code of conduct for the Cookiecutter project's codebases and documentation expects everyone interacting in the project to follow the [PyPA Code of Conduct](https://www.pypa.io/en/latest/code-of-conduct/). This applies to various forms of communication, including issue trackers, chat rooms, mailing lists, and both virtual and in-person interactions.\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is the code of conduct about?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chainlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
